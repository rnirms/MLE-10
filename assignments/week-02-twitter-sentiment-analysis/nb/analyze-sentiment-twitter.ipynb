{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d097db",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\"\n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>\n",
    "\n",
    "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Twitter Data</h1>\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "### ‚òëÔ∏è Objectives\n",
    "At the end of this session, you will be able to:\n",
    "- [ ] Understand how to find and run pre-trained models\n",
    "- [ ] Evaluate results from pre-trained models\n",
    "- [ ] Run a pre-trained model using real twitter data\n",
    "\n",
    "\n",
    "### üî® Pre-Assignment\n",
    "\n",
    "Create a new Conda environment for sentiment anaylsis (sa)\n",
    "\n",
    "```bash\n",
    "  conda create -n sa python=3.8 jupyter -y\n",
    "```\n",
    "\n",
    "Activate your new environment\n",
    "```bash\n",
    "  conda activate sa\n",
    "```\n",
    "\n",
    "Open the jupyter-notebook\n",
    "```bash\n",
    "  jupyter-notebook\n",
    "```\n",
    "\n",
    "Navigate through the repo in the notebook to find `imports.ipynb` for this week and open it.\n",
    "\n",
    "Run all of the cells in the notebook.\n",
    "\n",
    "\n",
    "### Background\n",
    "Please review the weekly narrative [here](https://www.notion.so/Week-2-Data-Centric-AI-the-AI-Product-Lifecycle-72a84c1517b44fcbb3e6bd11d47477dc#2b73937612bb46559f5b91dc2bf55e7d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3934e6e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5ab14",
   "metadata": {},
   "source": [
    "## üöÄ Let's Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea542cb",
   "metadata": {},
   "source": [
    "Let's first start with our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67dcb2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv # Allows us to read and write csv files\n",
    "from pprint import pprint # Make our print functions easier to read\n",
    "\n",
    "from transformers import pipeline # Hugging face pipeline to load online models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4028f",
   "metadata": {},
   "source": [
    "ü§ó Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\n",
    "\n",
    "These models can be applied on:\n",
    "- üìù Text, for tasks like text classification, information extraction, question answering, summarization, translation, text generation, in over 100 languages.\n",
    "\n",
    "- üñºÔ∏è Images, for tasks like image classification, object detection, and segmentation.\n",
    "- üó£Ô∏è Audio, for tasks like speech recognition and audio classification.\n",
    "\n",
    "This is the pipeline method in transformers that we'll be using to analyze our sentiment data. Since we're not specifying a pretrained model, the pipeline has a default sentiment analysis model called [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30b34b2",
   "metadata": {},
   "source": [
    "In this example, we'll supply two polar sentiments and test out the model pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"This is great!\", \"Oh no!\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d04139",
   "metadata": {},
   "source": [
    "The `label` in this case indicates the prediction for the sentiment type.\n",
    "\n",
    "The `score` indicates the confidence of the prediction (between 0 and 1).\n",
    "\n",
    "Since our sentiments were very polar, it was easier for the model to predict the sentiment type.\n",
    "\n",
    "Let's see what happens when we use a less clear example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenging_sentiments = [\"I don't think freddriq should leave, he's been helpful.\",\n",
    "                          \"Is that the lake we went to last month?\"]\n",
    "sentiment_pipeline(challenging_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b62d4",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Loading the Twitter Data\n",
    "\n",
    "Let's play with some twitter data. We'll be using a modified version of the [Elon Musk twitter dataset on Kaggle](https://www.kaggle.com/datasets/andradaolteanu/all-elon-musks-tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/elonmusk_tweets.csv', newline='', encoding='utf8') as f:\n",
    "    tweets=[]\n",
    "    reader = csv.reader(f)\n",
    "    twitter_data = list(reader)\n",
    "    for tweet in twitter_data:\n",
    "        tweets.append(tweet[0])\n",
    "\n",
    "pprint(tweets[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630a8f1",
   "metadata": {},
   "source": [
    "First things first - let's look at the sentiment as determined by the [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) (default model) in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b10279",
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_sentiment = sentiment_pipeline(tweets[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3fefd",
   "metadata": {},
   "source": [
    "Let's check out the distribution of positive/negative Tweets and see the breakdown using Python's üêç standard library `collections.Counter`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tweet_distro = Counter([x['label'] for x in distil_sentiment])\n",
    "pos_sent_count = tweet_distro['POSITIVE']\n",
    "neg_sent_count = tweet_distro['NEGATIVE']\n",
    "total_sent_count = sum(tweet_distro.values())\n",
    "\n",
    "print(f\"{pos_sent_count} ({pos_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are positive.\")\n",
    "print(f\"{neg_sent_count} ({neg_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are negative.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42155a0c",
   "metadata": {},
   "source": [
    "Let's do that process again, but use a model with an additional potential label \"NEUTRAL\" called [bertweet-sentiment-analysis](https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis)\n",
    "\n",
    "To start - we'll build a pipeline with the new model by using the ü§ó Hugging Face address: `finiteautomata/bertweet-base-sentiment-analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet_pipeline = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025127d",
   "metadata": {},
   "source": [
    "Next, and the same as before, let's run the analysis on 100 of Elon's tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_sentiment = bertweet_pipeline(tweets[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a316d",
   "metadata": {},
   "source": [
    "And then, let's check out the breakdown of positive, negative, AND neutral sentiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tweet_distro = Counter([x['label'] for x in bert_sentiment])\n",
    "pos_sent_count = tweet_distro['POS']\n",
    "neu_sent_count = tweet_distro['NEU']\n",
    "neg_sent_count = tweet_distro['NEG']\n",
    "total_sent_count = sum(tweet_distro.values())\n",
    "\n",
    "print(f\"{pos_sent_count} ({pos_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are positive.\")\n",
    "print(f\"{neu_sent_count} ({neu_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are neutral.\")\n",
    "print(f\"{neg_sent_count} ({neg_sent_count / total_sent_count * 100:.2f}%) of the tweets classified are negative.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185798d",
   "metadata": {},
   "source": [
    "‚ùì What do you notice about the difference in the results? \n",
    "\n",
    "‚ùì Do the results for the `bertweet-base` model look better, or worse, than the results for the `distilbert-base` model? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684f9ae",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Partner Exercise\n",
    "\n",
    "With your partner, try and determine what the following tweets might be classified as. Try to classify them into the same groups as both of the model pipelines we saw today - and try adding a few of your own sentences/Tweets! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc55db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_difficult_tweets = [\n",
    "    \"Kong vs Godzilla has record for most meth ever consumed in a writer's room\",\n",
    "    \"@ashleevance Battery energy density is the key to electric aircraft. Autonomy for aircraft could have been done a long time ago. Modern airliners are very close to autonomous.\",\n",
    "    \"Tesla's action is not directly reflective of my opinion. Having some Bitcoin, which is simply a less dumb form of liquidity than cash, is adventurous enough for an S&P500 company.\",\n",
    "    \"<ADD YOUR OWN OPTION HERE>\",\n",
    "    \"<ADD YOUR OWN OPTION HERE>\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e3837",
   "metadata": {},
   "source": [
    "The `distilbert-base` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd3d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in example_difficult_tweets[0:1000]:\n",
    "    pprint(sentiment_pipeline(tweet))\n",
    "    print(tweet + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61230295",
   "metadata": {},
   "source": [
    "The `bertweet-base` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in example_difficult_tweets[0:1000]:\n",
    "    pprint(bertweet_pipeline(tweet))\n",
    "    print(tweet + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2c1c5",
   "metadata": {},
   "source": [
    "‚ùì How did you do? Did you find any surprising results? \n",
    "\n",
    "‚ùì Are there any instances where the two models gave different predictions for the same tweet?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fourthbrain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "635e31ff34c0350df6e9d804eda70786d94f48b17fcc73c378df4ea6ec0d01fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
